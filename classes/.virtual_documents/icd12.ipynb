








# Importar datos
from sklearn.datasets import load_iris
iris = load_iris()

# Crear un DataFrame de Pandas
import pandas as pd
df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
df['species'] = iris.target

# Separar vector de características (X_i) y etiquetas (y)
X = df.drop('species', axis=1)
y = df['species']





from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

# Establecer algoritmos de inferencia
models = {
    "Naive Bayes": GaussianNB(),
    "C4.5 (Decision Tree)": DecisionTreeClassifier(),
    "k-Nearest Neighbors": KNeighborsClassifier(),
    "Support Vector Machine": SVC()
}





# Partición de los datos 80% training, 20% testing
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)





# Construir modelo con datos de training
clf = GaussianNB().fit(X_train, y_train)

# Evaluar modelo con datos de testing (mostrar accuracy)
clf.score(X_test, y_test)





results = {} 
for name, model in models.items():
    clf = model.fit(X_train, y_train)
    cv_results = clf.score(X_test, y_test)
    results[name] = cv_results
    print(f"{name}: {cv_results.mean():.4f}")











from sklearn.model_selection import cross_val_score

clf = GaussianNB()

# Training y testing en una sola función
scores = cross_val_score(clf, X, y, cv=5)

print("Resultados para cada iteración: ", scores)

print("Resultado promedio: ", scores.mean())





from sklearn.model_selection import StratifiedKFold

# Realizar particiones de los datos 
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)

# Visualizar los índices para las particiones
#for train, test in skf.split(X, y): print("%s %s" % (train, test))


acc_scores = []

for train_index, test_index in skf.split(X, y):
    # Particiones para training
    X_train_fold = X.iloc[train_index]
    y_train_fold = y.iloc[train_index]
    # Particiones para testing
    X_test_fold = X.iloc[test_index]
    y_test_fold = y.iloc[test_index]
    # Entrenamiento del modelo
    clf = GaussianNB().fit(X_train_fold, y_train_fold)
    # Evaluación de modelo y se acumula el accuracy
    acc = clf.score(X_test_fold, y_test_fold)
    print("Fold accuracy: ", acc)
    acc_scores.append(acc)    

from statistics import mean, stdev
print('Overall Accuracy:', mean(acc_scores))
print('Standard Deviation is:', stdev(acc_scores))





from sklearn.metrics import accuracy_score

# Iterar sobre los modelos
for name, model in models.items():
    acc_scores = []
    # Iterar sobre las particiones de los datos
    for train_index, test_index in skf.split(X, y):
        # Particiones para training y testing
        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]
        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]
        # Entrenamiento y evaluación del modelo
        model.fit(X_train_fold, y_train_fold)
        y_predict = model.predict(X_test_fold)
        acc = accuracy_score(y_test_fold, y_predict)
        print("Fold accuracy: ", acc)
        acc_scores.append(acc)
        
    avg_acc = sum(acc_scores)/len(acc_scores)
    print(f"{name}: Avg accuracy {avg_acc:.4f}")

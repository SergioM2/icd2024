





!pip install keras
!pip install tensorflow
!pip install Augmentor
!pip install tensorflow-io
!pip install IPython
!pip install textattack








# Importing necessary functions
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import array_to_img, img_to_array, load_img


# Initialising the ImageDataGenerator class.
# We will pass in the augmentation parameters in the constructor.
datagen = ImageDataGenerator(
    rotation_range = 40,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True,
    brightness_range = (0.5, 1.5))


from google.colab import drive
drive.mount('/content/drive')


path = 'drive/MyDrive/ICD/ICD6/images/'
# Loading a sample image
img = load_img(path+'test_image.jpg') # this is a PIL image
# Converting the input sample image to an array
x = img_to_array(img) # this is a Numpy array with shape (3, 150, 150)
# Reshaping the input image
x = x.reshape((1, ) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)


# Generating and saving 5 augmented samples using the above defined parameters.
i = 0
for batch in datagen.flow(x, batch_size = 1, save_to_dir ='drive/MyDrive/ICD/ICD6/new_images', save_prefix ='image', save_format ='jpg'):
    i += 1
    if i > 5:
        break





# Importing necessary library
import Augmentor
# Passing the path of the image directory
p = Augmentor.Pipeline(path)


# Defining augmentation parameters and generating 5 samples
p.flip_left_right(0.5)
p.black_and_white(0.1)
p.rotate(0.3, 10, 10)
p.skew(0.4, 0.5)
p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)
p.sample(5)





#importing necessary libraries
import tensorflow as tf
import tensorflow_io as tfio
import IPython
import numpy as np


path = 'drive/MyDrive/ICD/ICD6/audios/'
#to play the audio
IPython.display.Audio(path+"test_audio.wav")


#loading and reading the audio file.
audio_data = tfio.audio.AudioIOTensor(path+"test_audio.wav")
print(audio_data)
print(audio_data.shape)
print(audio_data.rate)


#perform slicing
audio_sl = audio_data[5000:]
print('Shape After Slicing :',audio_sl.shape)

#last dimension is ignored.
audio_t = tf.squeeze(audio_sl, axis=[-1])
print('Shape After squeezing:',audio_t.shape)


#to play the audio,
from IPython.display import Audio
Audio(audio_t.numpy(), rate=audio_data.rate.numpy())


# convert tensor to float datatype,.
tensor = tf.cast(audio_t, tf.float32) / 32767.0
print(tensor)

#plot the graph.
import matplotlib.pyplot as plt
plt.figure()
plt.plot(tensor.numpy())
plt.show()





# Trim silence from the beginning and end of the audio signal
trimed = tfio.audio.trim(tensor,
                         axis=0,
                         epsilon=0.02)
print('Trimmed :',trimed)


#Mention the stating and ending limit
start = trimed[0]
stop = trimed[1]
print("START:{},\nSTOP :{}".format(start.numpy(),stop.numpy()))

trimmed_audio = tensor[start:stop]
print('Trimmed Audio shape:',trimmed_audio.shape)

plt.figure()
plt.plot(trimmed_audio.numpy())


#to play the audio,
Audio(trimmed_audio.numpy(), rate=audio_data.rate.numpy())





#Apply a fade-in and fade_out effect with a duration
audio_fade = tfio.audio.fade(trimmed_audio, fade_in=20000, fade_out=20000, mode="logarithmic")

plt.figure()
#plotting the faded audio.
plt.plot(audio_fade.numpy())


#to plat the audio
Audio(audio_fade.numpy(), rate=audio_data.rate.numpy())





# adding noise to audio
noise_factor = 0.005
noise = np.random.randn(len(audio_fade))
audio_augmented = audio_fade + noise_factor * noise

plt.figure()
plt.plot(audio_augmented.numpy())


Audio(audio_augmented.numpy(), rate=audio_data.rate.numpy())





shift_max = 1
shift_direction = 'right'
shift = np.random.randint(audio_data.rate.numpy() * shift_max)
if shift_direction == 'right':
    shift = -shift
audio_shifted = np.roll(audio_augmented.numpy(), shift)

# Set to silence for heading/ tailing
#if shift > 0:
    #audio_shifted[:shift] = 0
#else:
    #audio_shifted[shift:] = 0

plt.figure()
plt.plot(audio_shifted)


Audio(audio_shifted, rate=audio_data.rate.numpy())





import librosa
audio_pitch = librosa.effects.pitch_shift(audio_shifted, sr=audio_data.rate.numpy(), n_steps=4)
plt.figure()
plt.plot(audio_pitch)


Audio(audio_pitch, rate=audio_data.rate.numpy())





audio_speed = librosa.effects.time_stretch(audio_pitch, rate=0.5)
plt.figure()
plt.plot(audio_speed)


Audio(audio_speed, rate=audio_data.rate.numpy())








from textattack.augmentation import WordNetAugmenter
text = "start each day with positive thoughts and make your day"
wordnet_aug = WordNetAugmenter()
wordnet_aug.augment(text)





from textattack.augmentation import EmbeddingAugmenter
embed_aug = EmbeddingAugmenter()
embed_aug.augment(text)





from textattack.augmentation import CharSwapAugmenter
charswap_aug = CharSwapAugmenter()
charswap_aug.augment(text)





from textattack.augmentation import CheckListAugmenter
checklist_aug = CheckListAugmenter()
checklist_aug.augment(text)





from textattack.augmentation import EasyDataAugmenter
eda_aug = EasyDataAugmenter()
eda_aug.augment(text)













import statsmodels.api as sm
import pandas as pd
import numpy as np








# loading the training dataset 
df = pd.read_csv('logit_train.csv', index_col = 0)
df.describe()





# defining the dependent and independent variables
X_train = df[['gmat', 'gpa', 'work_experience']]
y_train = df[['admitted']]

print(X_train.head())
print(y_train.head())





import seaborn as sns
import matplotlib.pyplot as plt

iris_pairplot = sns.pairplot(df, height=2, aspect=1, corner=True)

## Define function to plot a single regression line
def regline(x, y, **kwargs):
    sns.regplot(data=kwargs['data'], x=x.name, y=y.name, scatter=False, color=kwargs['color'])

## Call the function for each non-diagonal subplot within pairplot
iris_pairplot.map_offdiag(regline, color='red', data=df)

plt.tight_layout()
plt.show()








# building the model and fitting the data
log_reg = sm.Logit(y_train, X_train).fit()








# printing the summary table
print(log_reg.summary())











# loading the testing dataset  
df = pd.read_csv('logit_test.csv', index_col = 0)
  
# defining the dependent and independent variables
X_test = df[['gmat', 'gpa', 'work_experience']]
y_test = df['admitted']
  
# performing predictions on the test dataset
y_hat = log_reg.predict(X_test)
prediction = list(map(round, y_hat))
print('y_hat:\n', y_hat)
  
# comparing original and predicted values of y
print('Actual values', list(y_test.values))
print('Predictions :', prediction)





def create_confusion_matrix(y_true, y_pred):
    # Crear una matriz de confusi√≥n de 2x2 inicializada en ceros
    confusion_matrix = np.zeros((2, 2), dtype=int)

    # Iterar sobre las etiquetas verdaderas y predicciones para actualizar la matriz
    for i in range(len(y_true)):
        confusion_matrix[y_true[i], y_pred[i]] += 1

    return confusion_matrix

def calculate_accuracy(confusion_matrix):
    # TP: Verdaderos positivos (estudiantes admitidos que fueron correctamente clasificados como admitidos).
    TP = confusion_matrix[1, 1]
    # TN: Verdaderos negativos (estudiantes no admitidos que fueron correctamente clasificados como no admitidos).
    TN = confusion_matrix[0, 0]
    # FP: Falsos positivos (estudiantes no admitidos que fueron incorrectamente clasificados como admitidos).
    FP = confusion_matrix[0, 1]
    # FN: Falsos negativos (estudiantes admitidos que fueron incorrectamente clasificados como no admitidos).
    FN = confusion_matrix[1, 0]

    accuracy = (TP + TN) / (TP + TN + FP + FN)

    return accuracy


# Confusion matrix from predicitions
cm = create_confusion_matrix(y_test.values, prediction)
print("Confusion Matrix:\n", cm)

# accuracy score of the model
print('Test accuracy = ', calculate_accuracy(cm))





# import the class
from sklearn.linear_model import LogisticRegression

# instantiate the model (using the default parameters)
logreg = LogisticRegression()

# fit the model with data
logreg.fit(X_train, y_train.values.ravel())


y_pred = logreg.predict(X_test)

# comparing original and predicted values of y
print('Actual values', list(y_test.values))
print('Predictions :', y_pred)


from sklearn.metrics import (confusion_matrix, accuracy_score)
  
# confusion matrix
cm = confusion_matrix(y_test, y_pred) 
print ("Confusion Matrix : \n", cm) 
  
# accuracy score of the model
print('Test accuracy = ', accuracy_score(y_test, y_pred))



